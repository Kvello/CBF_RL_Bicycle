wandb_project: "ppo-quadrotor"

env:
  name: quadrotor
  gamma: 0.99
  # These arguments are passed to the environment constructor
  cfg:
    done_on_violation: false
    obs_signals: ["obs"]
    ref_signals: ["ref"]
    full_obs_key: "observation_extended"
    safety_obs_key: "observation"
    max_steps: 599 # < episode_len_sec*ctrl_freq
    num_parallel_env: 8  #rule of thumb: <=frames_per_batch / max_steps
    params:
      max_input: 1.0
models:
  value_net:
    name: feedforward
    eps: 0.0
    layers: [64, 64]
    activation: relu

  policy_net:
    name: feedforward
    layers: [64, 64]
    activation: relu

algorithm:
  name: ppo
  num_epochs: 10
  frames_per_batch: 8192   # 2**13
  sub_batch_size: 256      # 2**8
  max_grad_norm: 1.0
  total_frames: 1048576     # 2**20
  clip_epsilon: 0.2
  lmbda: 0.95
  critic_coef: 1.0
  supervision_coef: 0.0
  collision_buffer_size: 0  # same as frames_per_batch
  primary_reward_key: reward
  secondary_reward_key: neg_cost #Ignored but plotted for PPO with performance objective only
  entropy_coef: 0.001
  loss_critic_type: smooth_l1
  optim_kwargs:
    lr: 1.0e-4
  scheduler: null

evaluation:
  eval_steps: 1200

render:
  render: true
  num_frames: 1800
  fps : 30


